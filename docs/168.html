<html>
<head>
<title>Kubernetes HPA Autoscaling with Custom and External Metrics - Using GKE and Stackdriver Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Kubernetes HPA使用自定义和外部指标进行自动扩展——使用GKE和堆栈驱动指标</h1>
<blockquote>原文：<a href="https://www.fairwinds.com/blog/kubernetes-hpa-autoscaling-with-custom-and-external-metrics-using-gke-and-stackdriver-metrics#2020-07-17">https://www.fairwinds.com/blog/kubernetes-hpa-autoscaling-with-custom-and-external-metrics-using-gke-and-stackdriver-metrics#2020-07-17</a></blockquote><div><span id="hs_cos_wrapper_post_body" class="hs_cos_wrapper hs_cos_wrapper_meta_field hs_cos_wrapper_type_rich_text" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;kubernetes deployment autoscaling &quot;}" data-sheets-userformat="{&quot;2&quot;:513,&quot;3&quot;:{&quot;1&quot;:0},&quot;12&quot;:0}"> Kubernetes部署自动扩展</span>更令人兴奋，因为HorizontalPodAutoscaler可以根据自定义和外部指标进行扩展，而不是像以前那样简单地扩展CPU和内存。</p>

<p>在这篇文章中，我将回顾HPA是如何工作的，自定义和外部指标API是什么，然后看一个例子，在这个例子中我配置了<span data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;kubernetes deployment autoscaling &quot;}" data-sheets-userformat="{&quot;2&quot;:513,&quot;3&quot;:{&quot;1&quot;:0},&quot;12&quot;:0}"> Kubernetes deployment </span>基于外部Nginx指标自动扩展应用程序。</p>
<h4><strong>背景</strong></h4>
<p><strong/><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#how-does-the-horizontal-pod-autoscaler-work" data-href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#how-does-the-horizontal-pod-autoscaler-work" rel="nofollow noopener" target="_blank"><strong>卧式吊舱自动缩放器如何工作</strong> </a></p>
<p>HPA被实现为控制回路。这个循环每30秒向metrics api发出一个请求，以获取当前pod指标的统计信息。然后，它会计算当前pod指标是否超过其任何目标值。如果是这样，它会增加部署对象的数量。我认为这篇关于自动缩放器的自动缩放算法的文档非常值得一读。</p>
<p>实际上，HPA控制器从三个不同的API获得指标:<code>metrics.k8s.io</code>、<code>custom.metrics.k8s.io</code>和<code>external.metrics.k8s.io</code>、<strong>。Kubernetes很棒，因为你可以扩展它的API，这就是这些度量API的设计方式。资源指标，即<code>metrics.k8s.io</code> API，是由<a href="https://github.com/kubernetes-incubator/metrics-server" data-href="https://github.com/kubernetes-incubator/metrics-server" rel="nofollow noopener" target="_blank">指标服务器</a>实现的。对于自定义和外部指标，API由第三方供应商实施，或者您可以自己编写。目前我所知道的<a href="https://github.com/directxman12/k8s-prometheus-adapter" data-href="https://github.com/directxman12/k8s-prometheus-adapter" rel="noopener nofollow" target="_blank"> prometheus适配器</a>和<a href="https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api" data-href="https://github.com/kubernetes/metrics/blob/master/IMPLEMENTATIONS.md#custom-metrics-api" rel="noopener nofollow" target="_blank"> custom </a>和<a href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter" data-href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter" rel="noopener nofollow" target="_blank"> stackdriver适配器</a>都实现了自定义和外部度量API。详情请查看主题上的这些k8s文档。</strong></p>
<h4>基于外部指标的扩展示例</h4>
<p>下面是我创建的一个例子，它使用来自Stackdriver的指标来扩展在<a href="https://cloud.google.com/kubernetes-engine/" data-href="https://cloud.google.com/kubernetes-engine/" rel="noopener nofollow" target="_blank"> GKE集群</a>上运行的Kubernetes部署。然而，我没有使用Stackdriver默认拥有的指标，而是将外部指标从Nginx指标传送到Stackdriver，然后使用这些指标来扩展我的应用程序。下面我描述了我实现这个目标的步骤。<a href="https://github.com/JessicaGreben/example-external-custom-metrics" data-href="https://github.com/JessicaGreben/example-external-custom-metrics" rel="noopener nofollow" target="_blank">本回购</a>对此有示例代码。</p>
<p>设置步骤:</p>
<ul>
<li>创建GKE集群(&gt; 1.10版)</li>
<li>启用Stackdriver监控(创建stackdriver帐户)</li>
</ul>
<p>我的目标是添加一个水平pod自动缩放器，它将根据HPA从Stackdriver获得的Nginx外部指标来缩放我的部署。</p>
<p><strong>以下是我为此采取的高级步骤:</strong></p>
<ul>
<li>确认度量服务器正在Kubernetes集群中运行。</li>
<li>部署实现定制和外部度量API的外部度量服务器。</li>
<li>部署一个nginx入口控制器，带有一个<a href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/prometheus-to-sd" data-href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/prometheus-to-sd" rel="nofollow noopener" target="_blank"> sidecar pod </a>，它将从Nginx中抓取普罗米修斯格式的指标，并将它们发送到stackdriver。</li>
<li>使用基于nginx指标扩展部署的<a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" data-href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" rel="nofollow noopener" target="_blank"> HPA </a>部署我的应用程序。</li>
</ul>
<p>参考资料:</p>

<p>以下是相同步骤的更详细版本:</p>
<ul>
<li>1.确保度量服务器正在Kubernetes集群中运行。在GKE，默认情况下会启动公制服务器。否则，可以按照<a href="https://github.com/kubernetes-incubator/metrics-server#deployment" data-href="https://github.com/kubernetes-incubator/metrics-server#deployment" rel="nofollow noopener" target="_blank">公制服务器自述文件</a>上的信息或使用<a href="https://github.com/helm/charts/tree/master/stable/metrics-server" data-href="https://github.com/helm/charts/tree/master/stable/metrics-server" rel="nofollow noopener" target="_blank">公制服务器导航图</a>启动公制服务。</li>
</ul>
<pre># check if the metric server is deployed (or heapster if before v1.11)
$ kubectl get deploy --all-namespaces
[...deleted...]      
kube-system   metrics-server-v0.2.1                 1         1 
kube-system   heapster-v1.5.3                       1         1
# make a request to the metrics api to show that its available
$ kubectl get --raw "/apis/metrics.k8s.io/" | jq
{
  "kind": "APIGroup",
  "apiVersion": "v1",
  "name": "metrics.k8s.io",
  "versions": [
    {
      "groupVersion": "metrics.k8s.io/v1beta1",
      "version": "v1beta1"
    }
  ],
  "preferredVersion": {
    "groupVersion": "metrics.k8s.io/v1beta1",
    "version": "v1beta1"
  },
  "serverAddressByClientCIDRs": null
}</pre>
<p>您可以看到外部指标API和自定义指标API还不可用。</p>
<pre>$ kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1" | jq
Error from server (NotFound): the server could not find the requested resource
$ kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1"
Error from server (NotFound): the server could not find the requested resource</pre>
<p>让我们解决这个问题。</p>

<p>按照<a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/external-metrics-autoscaling" data-href="https://cloud.google.com/kubernetes-engine/docs/tutorials/external-metrics-autoscaling" rel="noopener nofollow" target="_blank"> google docs </a>中的步骤，我部署了stackdriver适配器:</p>
<pre>$ kubectl create clusterrolebinding cluster-admin-binding \ 
 --clusterrole cluster-admin \
 --user "$(gcloud config get-value avvount)"
clusterrolebinding.rbac.authorization.k8s.io/cluster-admin-binding created

$ kubectl create -f
https://raw.githubusercontent.com/GoogleCloudPlatform/k8s-stackdriver/master/custom-metrics-stackdriver-adapter/deploy/production/adapter.yaml
</pre>
<p> </p>
<pre># confirm it deployed happily
$ kubectl get po --all-namespaces
custom-metrics custom-metrics-stackdriver-adapter-c4d98dc54-xq8bj 1/1 Running 0 51s</pre>
<p>检查Stackdriver部署是否成功，以及自定义和外部指标API现在是否可用:</p>
<p><br/> <br/></p>
<pre># confirm it deployed happily
$ kubectl get po --all-namespaces
custom-metrics custom-metrics-stackdriver-adapter-c4d98dc54-xq8bj 1/1 Running 0 51s</pre>
<pre># check to see if custom/external metrics api is up now
$ kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1" | jq
{
 "kind": "APIResourceList",
 "apiVersion": "v1",
 "groupVersion": "external.metrics.k8s.io/v1beta1",
 "resources": []
}</pre>
<pre>$ kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1" | jq
{
 "kind": "APIResourceList",
 "apiVersion": "v1",
 "groupVersion": "custom.metrics.k8s.io/v1beta1",
 "resources": [
 {
 "name": "*/agent.googleapis.com|agent|api_request_count",
 "singularName": "",
 "namespaced": true,
 "kind": "MetricValueList",
 "verbs": [
 "get"
 ]
 },
[...lots more metrics...]
 {
 "name": "*/vpn.googleapis.com|tunnel_established",
 "singularName": "",
 "namespaced": true,
 "kind": "MetricValueList",
 "verbs": [
 "get"
 ]
 }
 ]
}</pre>
<p>有这么多自定义指标可供使用，这真是太酷了。但是，我想使用Nginx metrics中的一个外部指标。因此，我需要让nginx安装程序将其指标发送给stackdriver，这样这些指标也将可用。</p>
<ul>
<li>3.我用<a href="https://github.com/helm/charts/tree/master/stable/nginx-ingress" data-href="https://github.com/helm/charts/tree/master/stable/nginx-ingress" rel="noopener nofollow" target="_blank">官方掌舵图</a>部署了Nginx入口控制器。然后配置Nginx入口控制器将其指标发送给stackdriver。幸运的是，nginx入口控制器在端口<code>10254</code>已经有了一个路由<code>/metrics</code>，它以普罗米修斯格式公开了一堆指标(<a href="https://gist.github.com/JessicaGreben/b496fb802556646731df1f8c49e99e54" data-href="https://gist.github.com/JessicaGreben/b496fb802556646731df1f8c49e99e54" rel="noopener nofollow" target="_blank">这里是一个示例</a> <code>curl</code>请求Nginx指标端点查看公开的指标列表)。</li>
</ul>
<p>此外，stackdriver支持以普罗米修斯格式上传额外的指标。为了做到这一点，我使用Nginx入口控制器部署部署了<a href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/prometheus-to-sd" data-href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/prometheus-to-sd" rel="noopener nofollow" target="_blank">Prometheus-to-stack driver</a>sidecar。这个sidecar抓取度量，并把它们发送到stackdriver。</p>
<p><a href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/blob/master/prometheus-to-sd/kubernetes/prometheus-to-sd-kube-state-metrics.yaml#L26" data-href="https://github.com/GoogleCloudPlatform/k8s-stackdriver/blob/master/prometheus-to-sd/kubernetes/prometheus-to-sd-kube-state-metrics.yaml#L26" rel="nofollow noopener" target="_blank">使用这个如何创建sidecar的例子</a>，我将这个<code>prometheus-to-sd</code>容器添加到nginx-ingress-controller部署中，用指标的端口和路由配置<code>— source</code>:</p>
<pre><code>
- name: prometheus-to-sd
  image: gcr.io/google-containers/prometheus-to-sd:v0.2.1
  ports:
    - name: profiler
      containerPort: 6060
  command:
    - /monitor
    - --stackdriver-prefix=custom.googleapis.com
    - --source=nginx-ingress-controller:http://localhost:10254/metrics
    - --pod-id=$(POD_NAME)
    - --namespace-id=$(POD_NAMESPACE)
  env:
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
</code></pre>
<p>现在，我可以通过导航到Stackdriver指标仪表板来检查Stackdriver中是否有nginx外部指标:</p>
<figure><img src="../Images/33f0cca3bb8b928354b39b944781bf2c.png" alt="1_GQis3ESiQdZyuUi73_Qjcg" srcset="https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=400&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png 400w, https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=800&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png 800w, https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=1200&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png 1200w, https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=1600&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png 1600w, https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=2000&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png 2000w, https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=2400&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png 2400w" sizes="(max-width: 800px) 100vw, 800px" data-original-src="https://www.fairwinds.com/hs-fs/hubfs/1_GQis3ESiQdZyuUi73_Qjcg.png?width=800&amp;name=1_GQis3ESiQdZyuUi73_Qjcg.png"/></figure>
<p> </p>
<p>我还可以检查nginx指标现在在kubernetes外部指标api端点上是否可用。比如我可以检索<code>nginx_connections_total</code>的值。</p>
<pre>$ kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1/namespaces/default/custom.googleapis.com|nginx-ingress-controller|nginx_connections_total" | jq</pre>
<pre>{
 "kind": "ExternalMetricValueList",
 "apiVersion": "external.metrics.k8s.io/v1beta1",
 "metadata": {
     "selfLink": "/apis/external.metrics.k8s.io/v1beta1/namespaces/default/custom.googleapis.com%7Cnginx-ingress-controller%7Cnginx_connections_total"
     },
 "items": [
[...removed...]
     {
     "metricName": "custom.googleapis.com|nginx-ingress-controller|nginx_connections_total",
     "metricLabels": {
         "metric.labels.ingress_class": "nginx",
         "metric.labels.namespace": "",
         "metric.labels.state": "active",
         "resource.labels.cluster_name": "example-custom-metrics",
         "resource.labels.container_name": "",
         "resource.labels.instance_id": "gke-example-custom-metri-default-pool-43d79fe3-08rp.c.cluster-health-test.internal",
         "resource.labels.namespace_id": "default",
         "resource.labels.pod_id": "nginx-nginx-ingress-controller-df8dd967f-fvcx9",
         "resource.labels.project_id": "cluster-health-test",
         "resource.labels.zone": "us-central1-a",
         "resource.type": "gke_container"
     },
     "timestamp": "2018-07-22T21:22:48Z",
     "value": "0"
 },</pre>
<pre>[...removed...]
 ]
}</pre>
<ul>
<li>4.<a href="https://github.com/JessicaGreben/example-external-custom-metrics/tree/master/charts/example-nodejs-app" data-href="https://github.com/JessicaGreben/example-external-custom-metrics/tree/master/charts/example-nodejs-app" rel="noopener nofollow" target="_blank">这是我部署的一个样本nodejs应用的示例掌舵图</a>。现在可以使用外部和自定义指标了，我可以创建水平pod autoscaler来根据任何nginx指标扩展我的示例nodejs应用程序。例如，假设当有多个活动连接到nginx时，我想扩展应用程序。我可以创建一个HPA，当指标<code>nginx_connections_total</code>增加超过目标值1时，它将增加部署<code>example-nodejs-app</code>的副本数量。</li>
</ul>
<pre># hpa.yaml</pre>
<pre>apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
 name: example-hpa-external-metrics
spec:
 minReplicas: 1
 maxReplicas: 5
 metrics:
 - type: External
     external:
         metricName:  custom.googleapis.com|nginx-ingress-internal-controller|nginx_connections_total
         targetValue: 1
     scaleTargetRef:
         apiVersion: apps/v1
         kind: Deployment
         name: example-nodejs-app</pre>
<p>HPA显示当前有一个到nginx的连接，所以副本计数是1。如果nginx连接增加，pod副本也会增加。虽然nginx连接数的扩展可能不是扩展的最佳指标，但这是一个很好的例子，说明了所有这些是如何工作的。</p>
<pre>$ kubectl describe hpa example-hpa-external-metrics</pre>
<pre>Name: example-hpa-external-metrics
Namespace: default
Reference: Deployment/example-nodejs-app
Metrics:
"custom.googleapis.com|nginx-ingress_controller|nginx_connections_total" 
(target value): 1/ 1
Min replicas: 1
Max replicas: 5
Deployment pods: 1 current / 1 desired
Conditions:
 Type Status Reason Message
 ---- ------ ------ -------
 AbleToScale True ReadyForNewScale the last scale time was sufficiently old as to warrant a new scale</pre>
<pre> ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from external metric custom.googleapis.com|nginx-ingress-controller|nginx_connections_total(nil)
 
 ScalingLimited False DesiredWithinRange the desired count is within the acceptable range</pre>
<pre>Events: &lt;none&gt;</pre>
<p><strong>资源:</strong></p>

<p><span class="hs-cta-wrapper" id="hs-cta-wrapper-4f92c7e1-1646-4985-9a0a-b1091903dddb"><span class="hs-cta-node hs-cta-4f92c7e1-1646-4985-9a0a-b1091903dddb" id="hs-cta-4f92c7e1-1646-4985-9a0a-b1091903dddb"><a href="https://cta-redirect.hubspot.com/cta/redirect/2184645/4f92c7e1-1646-4985-9a0a-b1091903dddb"><img class="hs-cta-img" id="hs-cta-img-4f92c7e1-1646-4985-9a0a-b1091903dddb" src="../Images/b53e4ee22b6ef19bc06a035649ea1dc6.png" alt="Free Download: Kubernetes Best Practices Whitepaper" data-original-src="https://no-cache.hubspot.com/cta/default/2184645/4f92c7e1-1646-4985-9a0a-b1091903dddb.png"/></a></span>T6】</span></p></span></div>    
</body>
</html>